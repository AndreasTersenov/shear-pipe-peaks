{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271ebda-3d51-410d-b061-083744318b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd67a1-eb48-4cec-8cc9-dedb14fff783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycs.astro.wl.mass_mapping import *\n",
    "from pycs.sparsity.sparse2d.starlet import *\n",
    "from pycs.misc.cosmostat_init import *\n",
    "from pycs.astro.wl.hos_peaks_l1 import *\n",
    "import sp_peaks\n",
    "from sp_peaks import slics\n",
    "from sp_peaks import mapping\n",
    "from sp_peaks import summary_statistics\n",
    "from sp_peaks import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc4362-50fe-43d2-b5ee-7ca9c5008438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND PARAMETERS\n",
    "N_GAL = 7 \n",
    "SIZE_X_DEG = 10.\n",
    "SIZE_Y_DEG = 10.\n",
    "PIX_ARCMIN = 1.\n",
    "SHAPE_NOISE = 0.44\n",
    "NSCALES = 5\n",
    "MIN_SNR = -2\n",
    "MAX_SNR = 6\n",
    "NBINS=31\n",
    "NBINS_L1 = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ede08-de11-49b5-9562-25945d76b242",
   "metadata": {},
   "source": [
    "# Process Tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276248db-dced-482d-9e82-232e9da667d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shear_map(CATALOG_FILE, add_noise=True):\n",
    "    catalog_data = slics.read_catalogue_pd(CATALOG_FILE)\n",
    "    ra = catalog_data['RA']\n",
    "    dec = catalog_data['Dec']\n",
    "    g1_sim = catalog_data['gamma1_sim']\n",
    "    g2_sim = catalog_data['gamma2_sim']\n",
    "    \n",
    "    x, y = radec2xy(np.mean(ra), np.mean(dec), ra, dec)\n",
    "    Nx, Ny = int(SIZE_X_DEG / PIX_ARCMIN * 60), int(SIZE_Y_DEG / PIX_ARCMIN * 60)\n",
    "    galmap = bin2d(x, y, npix=(Nx, Ny))\n",
    "    mask = (galmap > 0).astype(int)\n",
    "\n",
    "    sigma_noise = np.zeros_like(galmap)\n",
    "    sigma_noise[mask != 0] = SHAPE_NOISE / np.sqrt(2 * galmap[mask != 0])\n",
    "    sigma_noise[mask == 0] = np.max(sigma_noise[mask != 0])\n",
    "    # noise_map = sigma_noise * np.random.randn(sigma_noise.shape[0], sigma_noise.shape[1])\n",
    "\n",
    "    e1map, e2map = bin2d(x, y, npix=(Nx, Ny), v=(g1_sim, g2_sim))\n",
    "\n",
    "    if add_noise:\n",
    "        # Add noise only if requested\n",
    "        noise_e1 = np.random.randn(*e1map.shape) * sigma_noise\n",
    "        noise_e2 = np.random.randn(*e2map.shape) * sigma_noise\n",
    "        e1map_noisy = e1map + noise_e1 * mask\n",
    "        e2map_noisy = e2map + noise_e2 * mask\n",
    "        return e1map_noisy, e2map_noisy, mask, sigma_noise\n",
    "    else:\n",
    "        # Return the maps without added noise\n",
    "        return e1map, e2map, mask, sigma_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5a66e-84df-41a7-b995-159b2775c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mass_map(e1map, e2map, mask, sigma_noise, method='ks'):\n",
    "    d = shear_data()\n",
    "    d.g1 = e1map\n",
    "    d.g2 = -e2map\n",
    "    (nx, ny) = e1map.shape\n",
    "    d.mask = mask\n",
    "    Ncov = np.zeros((nx, ny))\n",
    "    Ncov[mask > 0] = 2. * sigma_noise[mask > 0]**2\n",
    "    Ncov[mask == 0] = 1e9\n",
    "    d.Ncov = Ncov\n",
    "    d.nx = nx\n",
    "    d.ny = ny\n",
    "\n",
    "    if method == 'ks':\n",
    "        M = massmap2d(name='mass')\n",
    "        M.init_massmap(d.nx, d.ny)\n",
    "        M.DEF_niter = 50\n",
    "        M.niter_debias = 30\n",
    "        M.Verbose = False\n",
    "        ks = M.gamma_to_cf_kappa(e1map, -e2map)\n",
    "        ks = ks.real\n",
    "        return ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18620608-0c86-4bb1-be7b-48fc40c0ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistics(ks_noisy, sigma_noise, mask, nscales=NSCALES, min_snr=MIN_SNR, max_snr=MAX_SNR, nbins=NBINS, nbins_l1=NBINS_L1):\n",
    "    nx, ny = ks_noisy.shape\n",
    "    WT = starlet2d(gen2=False, l2norm=False, verb=False)\n",
    "    WT.init_starlet(nx, ny, nscale=nscales)\n",
    "    H = HOS_starlet_l1norm_peaks(WT)\n",
    "    H.set_bins(Min=min_snr, Max=max_snr, nbins=nbins)\n",
    "    H.set_data(ks_noisy, SigmaMap=sigma_noise, Mask=mask)\n",
    "    H.get_mono_scale_peaks(ks_noisy, sigma_noise, mask=mask)\n",
    "    H.get_wtpeaks(Mask=mask)\n",
    "    pc = H.Peaks_Count\n",
    "    H.get_wtl1(nbins_l1*2, Mask=mask)\n",
    "\n",
    "    H.plot_mono_peaks_histogram()\n",
    "    H.plot_peaks_histo(log_scale=True)\n",
    "    H.plot_l1norm()\n",
    "    \n",
    "    return H.Mono_Peaks_Count, H.Peaks_Count, H.l1norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bace91-877d-4154-b9b6-f460052e9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tile(filename, mass_mapping_method='ks', add_noise=False, save_mass_map=False, mass_map_output_file=None):\n",
    "    e1map, e2map, mask, sigma_noise = make_shear_map(filename, add_noise=add_noise)\n",
    "    ks = make_mass_map(e1map, e2map, mask, sigma_noise, method=mass_mapping_method)\n",
    "    ks_noisy = ks\n",
    "    peaks_mono, peaks_multi, l1norm = summary_statistics(ks_noisy, sigma_noise, mask)\n",
    "\n",
    "    if save_mass_map:\n",
    "        np.save(mass_map_output_file, ks*mask)\n",
    "\n",
    "    return peaks_mono, peaks_multi, l1norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa9e52-126f-4beb-ae67-5caa0a2da742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of usage\n",
    "filename = \"/n17data/tersenov/SLICS/Cosmo_DES/16_a/LOS4/DES_MocksCat_16_a_4_Bin3_LOS4_R4.dat\"\n",
    "mass_mapping_method = \"ks\"\n",
    "save_mass_map = False\n",
    "mass_map_output_file = None\n",
    "peaks_mono, peaks_multi, l1norm = process_tile(filename, mass_mapping_method, add_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4698f95-ea01-4eb7-87b0-a7b06dc0781f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70b3c8bc-2660-4cc4-aa25-d0ec0210a927",
   "metadata": {},
   "source": [
    "# Create lists of 19 tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff3a53-da24-4738-b387-243d5a6a7807",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "def create_grouped_lists_corrected(master_file_path, output_directory):\n",
    "    \"\"\"\n",
    "    Correctly creates and saves lists of filenames for each unique combination\n",
    "    of cosmology, seed, LOS, and bin, ensuring each file has only 19 paths.\n",
    "    \n",
    "    Args:\n",
    "        master_file_path (str): Path to the master file containing all filenames.\n",
    "        output_directory (str): Directory where the lists will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    # Initialize a dictionary for grouping filenames\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    with open(master_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            \n",
    "            # Extract the filename and split into components\n",
    "            parts = line.split('/')\n",
    "            filename = parts[-1]\n",
    "            file_parts = filename.split('_')\n",
    "            \n",
    "            # Extract cosmology, seed, LOS, and bin information correctly\n",
    "            cosmology = parts[-3]\n",
    "            seed = cosmology.split('_')[-1]\n",
    "            LOS = parts[-2]\n",
    "            bin_part = file_parts[5]  # Assuming \"BinX\" is the 7th element\n",
    "            \n",
    "            # Construct a unique key for grouping\n",
    "            key = (cosmology, seed, LOS, bin_part)\n",
    "            groups[key].append(line)\n",
    "    \n",
    "    # Save each group of filenames to a separate file\n",
    "    for (cosmology, seed, LOS, bin_part), filenames in groups.items():\n",
    "        # Naming the output file to reflect the group's unique combination\n",
    "        output_file_name = f\"{cosmology}_{LOS}_{bin_part}.txt\"\n",
    "        output_file_path = os.path.join(output_directory, output_file_name)\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            for filename in filenames:\n",
    "                output_file.write(filename + \"\\n\")\n",
    "\n",
    "master_file_path = \".././input/master_file.txt\"\n",
    "output_directory = \".././output/tiles_lists/\"\n",
    "create_grouped_lists_corrected(master_file_path, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5b1b1-0bf5-45f8-960a-d95fdbb2367f",
   "metadata": {},
   "source": [
    "# Process footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98629e5-95ca-4d8e-bcef-543d7d386fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "def process_footprint(file_list_path, output_dir=None, mass_mapping_method='ks', add_noise=True, save_mass_map=False, num_processes=19):\n",
    "    \"\"\"\n",
    "    Processes a footprint by parallelizing over the number of tiles in a footprint\n",
    "    and returns a single averaged vector for each summary statistic across all tiles.\n",
    "    \"\"\"\n",
    "    if save_mass_map and output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with open(file_list_path, 'r') as file:\n",
    "        filenames = file.read().splitlines()\n",
    "    \n",
    "    args = [(filename, mass_mapping_method, add_noise, save_mass_map, output_dir) for filename in filenames]\n",
    "    \n",
    "    with Pool(num_processes) as pool:\n",
    "        results = pool.map(worker, args)\n",
    "    \n",
    "    # Initialize lists to hold each type of summary statistic separately\n",
    "    SS_PC_data = []\n",
    "    MS_PC_data = []\n",
    "    l1_norm_data = []\n",
    "    \n",
    "    # Iterate over the results to collect the statistics\n",
    "    for SS_PC, MS_PC, l1_norm in results:\n",
    "        SS_PC_data.append(SS_PC)\n",
    "        MS_PC_data.append(MS_PC)\n",
    "        l1_norm_data.append(l1_norm)\n",
    "    \n",
    "    # Calculate the mean of each summary statistic across all tiles\n",
    "    SS_PC_mean = np.mean(SS_PC_data, axis=0)\n",
    "    MS_PC_mean = np.mean(MS_PC_data, axis=0)\n",
    "    l1_norm_mean = np.mean(l1_norm_data, axis=0)\n",
    "    \n",
    "    # Return the averaged statistics\n",
    "    return SS_PC_mean, MS_PC_mean, l1_norm_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c203f9-1cb7-4c55-b11f-e54327f5ecb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list_path = \".././output/tiles_lists/19_f_LOS2_Bin3.txt\" \n",
    "output_directory = '/n17data/tersenov/SLICS/Cosmo_DES/mass_maps'\n",
    "\n",
    "# Call process_footprint with your parameters\n",
    "SS_PC_mean, MS_PC_mean, l1_norm_mean = process_footprint(\n",
    "    file_list_path,\n",
    "    output_directory,\n",
    "    mass_mapping_method='ks', \n",
    "    save_mass_map=True,\n",
    "    num_processes=19\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc3efd-0a16-4098-96f4-a9d163507f53",
   "metadata": {},
   "source": [
    "# Process Cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262826b-8118-47f1-9b9f-5b1dbe3d8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process_cosmo(cosmology, cosmo_dir, output_dir, mass_mapping_method='ks', add_noise=True, save_mass_map=False, num_processes=19):\n",
    "    \"\"\"\n",
    "    Processes files for a specific cosmology by parallelizing over the tiles in a footprint\n",
    "    and organizes the summary statistics into separate arrays, accommodating full vectors.\n",
    "    \"\"\"\n",
    "    if save_mass_map and output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    list_files = glob(os.path.join(cosmo_dir, f\"{cosmology}_*.txt\"))\n",
    "    \n",
    "    # Initialize lists to hold the results for each statistic type\n",
    "    all_results = []\n",
    "\n",
    "    for file_path in list_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        parts = filename.rstrip('.txt').split('_')\n",
    "        bin, seed, LOS = parts[-1], parts[-3], parts[-2]  # Ensure this matches your file naming\n",
    "        \n",
    "        SS_PC_mean, MS_PC_mean, l1_norm_mean = process_footprint(\n",
    "            file_path,\n",
    "            output_dir,\n",
    "            mass_mapping_method,\n",
    "            add_noise,\n",
    "            save_mass_map,\n",
    "            num_processes\n",
    "        )\n",
    "        \n",
    "        # Append the results with full vectors preserved\n",
    "        all_results.append((cosmology, bin, seed, LOS, SS_PC_mean, MS_PC_mean, l1_norm_mean))\n",
    "    \n",
    "    # Define dtype with np.object_ for fields that will hold vectors\n",
    "    dtype = [('cosmology', 'U10'), ('bin', 'U10'), ('seed', 'U10'), ('LOS', 'U10'),\n",
    "             ('SS_PC_mean', np.object_), ('MS_PC_mean', np.object_), ('l1_norm_mean', np.object_)]\n",
    "    results_array = np.array(all_results, dtype=dtype)\n",
    "\n",
    "    # Save the results array to a numpy file\n",
    "    save_path = os.path.join(output_dir, f\"{cosmology}_{mass_mapping_method}_run.npy\")\n",
    "    np.save(save_path, results_array)\n",
    "\n",
    "    return results_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b2bec-964c-45c3-8c37-784b2594e9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cosmology = '19_f'  # Example cosmology\n",
    "cosmo_dir = \"../output/tiles_lists/\"  # Directory containing the list files\n",
    "output_directory = '/n17data/tersenov/SLICS/Cosmo_DES/summary_stats'  # Where to save the results\n",
    "\n",
    "# Process the specified cosmology and save the results\n",
    "final_results = process_cosmo(\n",
    "    cosmology,\n",
    "    cosmo_dir,\n",
    "    output_directory,\n",
    "    'ks',  # Example mass mapping method\n",
    "    True,  # Add noise\n",
    "    True,  # Save mass maps\n",
    "    19  # Number of processes\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
