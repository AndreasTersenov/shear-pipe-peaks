{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ebcbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lenspack.utils import bin2d\n",
    "from lenspack.image.inversion import ks93\n",
    "from lenspack.geometry.projections.gnom import radec2xy\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook creates a data file like peaks_mean_global.npy\n",
    "# tasks in this notebook\n",
    "#1. load catalog\n",
    "#2. calibrate shears\n",
    "#3. switch to pixels\n",
    "#4. bin galaxy shears\n",
    "#5. make map\n",
    "#6. cut out patches\n",
    "#7. gaussian filtering\n",
    "#8. divide by noise to get SNR maps\n",
    "#9. measure peaks\n",
    "#10. combine information from patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f030ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. load catalog\n",
    "dd = np.load('final_cat.npy', mmap_mode=None)\n",
    "dd.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89960c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. shear calibration\n",
    "# define shear response matrix (without R_s)\n",
    "DGAMMA=0.02\n",
    "R11=(dd['NGMIX_ELL_1P'][:,0]-dd['NGMIX_ELL_1M'][:,0])/DGAMMA\n",
    "R22=(dd['NGMIX_ELL_2P'][:,1]-dd['NGMIX_ELL_2M'][:,1])/DGAMMA\n",
    "R12=(dd['NGMIX_ELL_2P'][:,0]-dd['NGMIX_ELL_2M'][:,0])/DGAMMA\n",
    "R21=(dd['NGMIX_ELL_1P'][:,1]-dd['NGMIX_ELL_1M'][:,1])/DGAMMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cuts\n",
    "# shear independent- note: there are problems here, the mag cuts and star cuts are DEF shear dependent, and the star galaxy separation method has been updated\n",
    "shear_independent_cut = \\\n",
    "    (dd['SPREAD_MODEL']+2*dd['SPREADERR_MODEL'] > 0.0035) \\\n",
    "    & (dd['SPREAD_MODEL'] > 0.) \\\n",
    "    & (dd['SPREAD_MODEL'] < 0.03) \\\n",
    "    & (dd['FLAGS'] == 0) \\\n",
    "    & (dd['IMAFLAGS_ISO'] == 0) \\\n",
    "    & (dd['NGMIX_MCAL_FLAGS'] == 0) \\\n",
    "    & (dd['NGMIX_ELL_PSFo_NOSHEAR'][:,0] != -10) \\\n",
    "    & (dd['NGMIX_MOM_FAIL'] == 0) \\\n",
    "    & (dd['N_EPOCH'] > 0) \\\n",
    "    & (dd['NGMIX_N_EPOCH'] > 0)\n",
    "\n",
    "# shear dependent\n",
    "cutcat=[]\n",
    "shears=['NOSHEAR','1P','1M','2P','2M']\n",
    "for shear in shears:\n",
    "    # define cut quantities\n",
    "    snr_ngmix = dd['NGMIX_FLUX_'+shear]/dd['NGMIX_FLUX_ERR_'+shear]\n",
    "    rel_size = dd['NGMIX_T_'+shear]/dd['NGMIX_Tpsf_'+shear]\n",
    "    # cuts\n",
    "    snr_min= snr_ngmix > 10\n",
    "    snr_max= snr_ngmix < 500\n",
    "    rel_size_min = rel_size > np.sqrt(.5) \n",
    "    \n",
    "    good=(shear_independent_cut)&(snr_min)&(snr_max)&(rel_size_min)\n",
    "    \n",
    "    cutcat.append(good)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdf461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate selection response\n",
    "R11_s=((np.average(dd['NGMIX_ELL_NOSHEAR'][np.where(cutcat[1]),0])-np.average(dd['NGMIX_ELL_NOSHEAR'][np.where(cutcat[2]),0]))/DGAMMA)\n",
    "print(R11_s)\n",
    "R22_s=((np.average(dd['NGMIX_ELL_NOSHEAR'][np.where(cutcat[3]),1])-np.average(dd['NGMIX_ELL_NOSHEAR'][np.where(cutcat[4]),1]))/DGAMMA)\n",
    "print(R22_s)\n",
    "R12_s=((np.average(dd['NGMIX_ELL_NOSHEAR'][np.where(cutcat[3]),0])) - (np.average(dd['NGMIX_ELL_NOSHEAR'][np.where(cutcat[4]),0])))/(DGAMMA)\n",
    "print(R12_s)\n",
    "R21_s=((np.average(dd['NGMIX_ELL_NOSHEAR'][np.where(cutcat[1]),1])) - (np.average(dd['NGMIX_ELL_NOSHEAR'][np.where(cutcat[2]),1])))/DGAMMA\n",
    "print(R21_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2601ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total shear response and invert it (we can do this in a less dumb way later)\n",
    "R11_tot=np.mean(R11)+R11_s\n",
    "R22_tot=np.mean(R22)+R22_s\n",
    "R21_tot=np.mean(R21)+R21_s\n",
    "R12_tot=np.mean(R12)+R12_s\n",
    "print(R11_tot)\n",
    "print(R22_tot)\n",
    "DetR=(R11_tot*R22_tot-R21_tot*R12_tot)\n",
    "R11_inv=1/DetR*(R22_tot)\n",
    "R22_inv=1/DetR*(R11_tot)\n",
    "R12_inv=1/DetR*(-R12_tot)\n",
    "R21_inv=1/DetR*(-R21_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate shear\n",
    "g1_corr=R11_inv*dd['NGMIX_ELL_NOSHEAR'][:,0][cutcat[0]]\n",
    "g2_corr=R22_inv*dd['NGMIX_ELL_NOSHEAR'][:,1][cutcat[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8adec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(g1_corr)\n",
    "plt.hist(dd['NGMIX_ELL_NOSHEAR'][:,0][cutcat[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e43b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Compute number of pixels, Switch from RA, DEC to pixels\n",
    "# first, mask galaxies\n",
    "ra_ngmix = dd['XWIN_WORLD'][np.where(cutcat[0])]\n",
    "dec_ngmix = dd['YWIN_WORLD'][np.where(cutcat[0])]\n",
    "\n",
    "size_x_deg = 44\n",
    "size_y_deg = 16\n",
    "pixel_size_emap_amin=0.4\n",
    "\n",
    "Nx = int(size_x_deg / pixel_size_emap_amin * 60)\n",
    "Ny = int(size_y_deg / pixel_size_emap_amin * 60)\n",
    "\n",
    "print(Nx,Ny)\n",
    "import lenspack\n",
    "# Project (ra,dec) -> (x,y)\n",
    "x, y = radec2xy(np.mean(ra_ngmix), np.mean(dec_ngmix), ra_ngmix, dec_ngmix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. bin calibrated shears in 2D\n",
    "# v are the values, w is another option that tells you the weights\n",
    "# do we weight these? not according to what martin has\n",
    "# should we add the extent extent=(min_x[sh], max_x[sh], min_y[sh], max_y[sh])\n",
    "# used for extent? check if default is okay\n",
    "min_x = np.min(x)\n",
    "max_x = np.max(x)\n",
    "min_y = np.min(y)\n",
    "max_y = np.max(y)\n",
    "\n",
    "size_x = max_x - min_x\n",
    "size_y = max_y - min_y\n",
    "\n",
    "e1map, e2map = bin2d(x, y, npix=(Nx,Ny), v=(g1_corr,g2_corr))\n",
    "emap = np.array([e1map,e2map])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. make kappa map- note, the minus sign has to be here for our data conventions\n",
    "kappaE_cal, kappaB_cal = ks93(e1map,-e2map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. make cutouts here, size 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all remaining steps per cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c194cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. smooth kappa map with gaussian filter\n",
    "precision_Peaks = 2/pixel_size_emap_amin\n",
    "\n",
    "kappa_noisy_smoothed_cal = ndi.gaussian_filter(kappaE_cal, precision_Peaks) # Global\n",
    "kappa_noisy_smoothedB = ndi.gaussian_filter(kappaB_cal, precision_Peaks) #ei/Rii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. convert kappa map to SNR map\n",
    "\n",
    "# define noise properties \n",
    "#galaxy number density in gal/arcmin^2\n",
    "n_gal=7\n",
    "#pixel size in arcmin\n",
    "pix_arcmin=0.4\n",
    "#compute shape noise for CFIS\n",
    "shape_noise=0.44\n",
    "sigma_noise_CFIS=shape_noise/(np.sqrt(2*n_gal*pix_arcmin**2))\n",
    "# generate noise map\n",
    "noise_CFIS_z05=sigma_noise_CFIS*np.random.randn(512, 512)\n",
    "\n",
    "# compute snr map\n",
    "snr_cal = kappa_noisy_smoothed_cal/np.std(ndi.gaussian_filter(noise_CFIS_z05, precision_Peaks))\n",
    "snrB = kappa_noisy_smoothedB/np.std(ndi.gaussian_filter(noise_CFIS_z05, precision_Peaks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#8. measuring peaks\n",
    "# we want peak counts computed on SNR maps, but we can also compute them directly on kappa maps\n",
    "\n",
    "# run peak counts on kappa maps\n",
    "kappa_th = np.linspace(-0.06, 0.06, 31)\n",
    "kappa_th_center = 0.5*(kappa_th[:-1]+kappa_th[1:])\n",
    "\n",
    "peak_counts_cal, bins_cal = peaks.peaks_histogram(kappa_noisy_smoothed_cal,kappa_th)\n",
    "\n",
    "# compute peak counts on snr maps- this will look like input to likelihood code\n",
    "kappa_snr = np.linspace(-2,6,31)\n",
    "kappa_th_center_snr = 0.5*(kappa_snr[:-1]+kappa_snr[1:])\n",
    "\n",
    "peak_counts_cal_snr, bins_cal = peaks.peaks_histogram(snr_cal,kappa_snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot single-Gaussian peak counts- you can compare this for different mass mapping methods.  we can try per patch and also comparing the mean across 13 patches\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(kappa_th_center,peak_counts_cal,'b-',label='Global cal')\n",
    "plt.legend()\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlabel('kappa smooth', fontsize=18)\n",
    "plt.ylabel('peak counts', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of the peak counts from the 13 patches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
